{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "906ce1ed-cee8-4649-a33c-2bb9c4b1da35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from contextlib import nullcontext\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, date, timedelta, timezone\n",
    "import pytz\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from model import GPTConfig, GPT, load_model\n",
    "from data import data_columns, get_data_for_eval, decode_data, encode_data, get_ticker_data\n",
    "from stockdata import StockData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c12e9a18-1fe1-4bc3-bb9d-b5d1eee1129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "currentDir = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f815bf7-9a32-4621-a19a-d3cbb4d2ab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# configs\n",
    "# I/O\n",
    "out_dir = 'out'\n",
    "\n",
    "# system\n",
    "device = 'mps' # examples: 'cpu', 'cuda', 'cuda:0', 'cuda:1' etc., or try 'mps' on macbooks\n",
    "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16' # 'float32', 'bfloat16', or 'float16', the latter will auto implement a GradScaler\n",
    "\n",
    "# various inits, derived attributes, I/O setup\n",
    "seed_offset = 0\n",
    "\n",
    "torch.manual_seed(1337 + seed_offset)\n",
    "torch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul\n",
    "torch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn\n",
    "device_type = 'cuda' if 'cuda' in device else 'cpu' # for later use in torch.autocast\n",
    "# note: float16 data type will automatically use a GradScaler\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "552eefdf-9f80-4b8c-af06-0fb31748dd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns whether the final prediction is the same direction as the ground truth (e.g. both negative)\n",
    "def predict_and_plot(cutoff_date, predict_days, all_data_df, all_orig_df, model):\n",
    "    pred_is_correct = False\n",
    "    historical_datapoints = 40 # plot these on the graph as context\n",
    "    \n",
    "    if cutoff_date is None:\n",
    "        cutoff_date = datetime.now().date()\n",
    "    plt.figure(figsize=(10, 5)) \n",
    "    std_columns = ['close_std', 'open_std', 'high_std', 'low_std', 'volume_std', 'vix']\n",
    "    iter_count = 5\n",
    "    context_df = all_data_df[all_data_df.Date <= cutoff_date]\n",
    "    context = encode_data(context_df)\n",
    "    # std as delta percentage at the prediction cutoff date\n",
    "    cutoff_data = all_orig_df[all_orig_df.Date <= cutoff_date].iloc[-1]\n",
    "    std_close = cutoff_data.DeltaClose_std * cutoff_data.Close\n",
    "    last_close = cutoff_data.Close\n",
    "    print(f\"baseline {cutoff_data.Date} close {last_close} std_close {std_close}\")\n",
    "\n",
    "    preds = []\n",
    "    for i in range(iter_count):\n",
    "        y = model.generate(context.to(device), max_new_tokens=predict_days*len(data_columns), temperature=0.3)\n",
    "        pred = decode_data(y) # pred includes all the context\n",
    "        new_pred = pred[-predict_days:].copy().reset_index()\n",
    "        new_pred.loc[:, 'close_std'] = (new_pred.close_bucket - StockData.CLOSE_LABELS.min()).map(lambda x: StockData.BIN_VALUES[x])\n",
    "        new_pred.loc[:, 'open_std'] = (new_pred.open_bucket - StockData.OPEN_LABELS.min()).map(lambda x: StockData.BIN_VALUES[x])\n",
    "        new_pred.loc[:, 'high_std'] = (new_pred.high_bucket - StockData.HIGH_LABELS.min()).map(lambda x: StockData.BIN_VALUES[x])\n",
    "        new_pred.loc[:, 'low_std'] = (new_pred.low_bucket - StockData.LOW_LABELS.min()).map(lambda x: StockData.BIN_VALUES[x])\n",
    "        new_pred.loc[:, 'volume_std'] = (new_pred.volume_bucket  - StockData.VOLUME_LABELS.min()).map(lambda x: StockData.BIN_VALUES[x])\n",
    "        new_pred.loc[:, 'vix'] = (new_pred.vix_bucket  - StockData.VIX_LABELS.min()).map(lambda x: StockData.VIX_BINS[x])\n",
    "        # plt.plot(new_pred.close_std.cumsum() * std_close, label='prediction') \n",
    "    \n",
    "        preds.append(new_pred)\n",
    "    \n",
    "    new_pred = preds[0]\n",
    "    for i in range(1, len(preds)):\n",
    "        new_pred += preds[i]\n",
    "    new_pred /= len(preds)\n",
    "    new_pred['direction_color'] = 'red'\n",
    "    new_pred.loc[new_pred['close_direction'] <= (StockData.UP_LABEL + StockData.DOWN_LABEL)/2.0, 'direction_color'] = 'green'\n",
    "    \n",
    "    # We trust the direction prediction more. If the actual prediction differ, flip the price prediction direction\n",
    "    # new_pred.loc[(new_pred.direction_color == 'red') & (new_pred.close_std > 0), 'close_std'] *= -0\n",
    "    # new_pred.loc[(new_pred.direction_color == 'green') & (new_pred.close_std < 0), 'close_std'] *= -0\n",
    "    \n",
    "    print(f\"Predicting for dates > {context_df.iloc[-1].Date}\")\n",
    "    print(f\"=== close mean {new_pred.close_std.mean()} volume mean {new_pred.volume_std.mean()} vix {new_pred.vix.mean()+2.5} ===\")\n",
    "    print(f\"=== open mean {new_pred.open_std.mean()} high mean {new_pred.high_std.mean()} low mean {new_pred.low_std.mean()} ===\")\n",
    "    # print(new_pred[std_columns])\n",
    "    print(\"\")\n",
    "    pred_val_delta = new_pred.close_std.cumsum() * std_close\n",
    "    plt.scatter(y=pred_val_delta, x=new_pred.index + historical_datapoints, label='avg prediction', color=new_pred['direction_color']) \n",
    "    \n",
    "    # print out the ground truth\n",
    "    merged_orig = pd.merge(all_orig_df, all_data_df[['Date', 'tnx_bucket', 'vix_bucket']], on='Date', how='right')\n",
    "\n",
    "    ground_truth = merged_orig.iloc[len(context_df) - historical_datapoints:len(pred)].copy().reset_index()\n",
    "    ground_truth.loc[:, 'close_std'] = (ground_truth.close_bucket - StockData.CLOSE_LABELS.min()).map(lambda x: StockData.BIN_VALUES[x])\n",
    "    ground_truth.loc[:, 'open_std'] = (ground_truth.open_bucket - StockData.OPEN_LABELS.min()).map(lambda x: StockData.BIN_VALUES[x])\n",
    "    ground_truth.loc[:, 'high_std'] = (ground_truth.high_bucket - StockData.HIGH_LABELS.min()).map(lambda x: StockData.BIN_VALUES[x])\n",
    "    ground_truth.loc[:, 'low_std'] = (ground_truth.low_bucket - StockData.LOW_LABELS.min()).map(lambda x: StockData.BIN_VALUES[x])\n",
    "    ground_truth.loc[:, 'volume_std'] = (ground_truth.volume_bucket  - StockData.VOLUME_LABELS.min()).map(lambda x: StockData.BIN_VALUES[x])\n",
    "    ground_truth.loc[:, 'vix'] = (ground_truth.vix_bucket  - StockData.VIX_LABELS.min()).map(lambda x: StockData.VIX_BINS[x])\n",
    "    print(f\"=== ground truth from date (inclusive) {ground_truth.iloc[0].Date} ===\")\n",
    "    print(f\"=== close mean {ground_truth.close_std.mean()} volume mean {ground_truth.volume_std.mean()} vix mean {ground_truth.vix.mean()} ===\")\n",
    "    print(f\"=== open mean {ground_truth.open_std.mean()} high mean {ground_truth.high_std.mean()} low mean {ground_truth.low_std.mean()} ===\")\n",
    "    # print(ground_truth[std_columns])\n",
    "    # plt.plot(ground_truth.close_std.cumsum() * std_close, label='actual', color='black') \n",
    "    ground_truth_delta = ground_truth.Close - last_close\n",
    "    plt.plot(ground_truth_delta, label='original', color='blue') \n",
    "\n",
    "    if (pred_val_delta.iloc[-1] > 0) == (ground_truth_delta.iloc[-1] > 0):\n",
    "        pred_is_correct = True\n",
    "    \n",
    "    plt.legend()  # Adds a legend to distinguish the lines\n",
    "    plt.grid(True)\n",
    "    plt.show()  # Displays the plot\n",
    "    return pred_is_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "212e1e06-425d-442a-951d-2b5ab4d76736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model init\n",
    "# def load_model(device, out_dir, ckpt_file):\n",
    "#     model_args = dict()\n",
    "    \n",
    "#     ckpt_path = os.path.join(out_dir, ckpt_file)\n",
    "#     if not os.path.exists(ckpt_path):\n",
    "#         print(\"can't find checkpoint file: \" + ckpt_path)\n",
    "#         exit(1)\n",
    "    \n",
    "#     checkpoint = torch.load(ckpt_path, map_location=device, weights_only=False)\n",
    "#     checkpoint_model_args = checkpoint['model_args']\n",
    "#     # force these config attributes to be equal otherwise we can't even resume training\n",
    "#     # the rest of the attributes (e.g. dropout) can stay as desired from command line\n",
    "#     for k in ['n_layer', 'n_head', 'n_embd', 'block_size', 'bias', 'vocab_size']:\n",
    "#         model_args[k] = checkpoint_model_args[k]\n",
    "#     # create the model\n",
    "#     gptconf = GPTConfig(**model_args)\n",
    "#     model = GPT(gptconf)\n",
    "#     state_dict = checkpoint['model']\n",
    "#     # fix the keys of the state dictionary :(\n",
    "#     # honestly no idea how checkpoints sometimes get this prefix, have to debug more\n",
    "#     unwanted_prefix = '_orig_mod.'\n",
    "#     for k,v in list(state_dict.items()):\n",
    "#         if k.startswith(unwanted_prefix):\n",
    "#             state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "#     model.load_state_dict(state_dict)\n",
    "    \n",
    "#     model.to(device)\n",
    "#     model.eval()\n",
    "#     checkpoint = None # free up memory\n",
    "    \n",
    "#     print(gptconf)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b6c131b-ef89-45e5-8d13-35f497bf740f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(model, data_for_eval, ticker_df):\n",
    "    # Create a scrollable output widget with a fixed height of 500 pixels\n",
    "    output_area = widgets.Output(layout={'border': '1px solid black', 'width': '100%', 'height': '1000px', 'overflow_y': 'scroll'})\n",
    "    display(output_area)\n",
    "    \n",
    "    # Generate plots within the scrollable output area\n",
    "    with output_area:\n",
    "        correct_count = 0\n",
    "        total_count = 0\n",
    "        for year in range(2023, 2025):\n",
    "            for month in range(1, 13):\n",
    "                # day = random.randint(1, 28)\n",
    "                day = 6\n",
    "                correct = predict_and_plot(date(year, month, day), 20, data_for_eval, ticker_df, model)\n",
    "                total_count += 1\n",
    "                if correct:\n",
    "                    print(\"correct\")\n",
    "                    correct_count += 1\n",
    "    \n",
    "        print(f\"correction predictions {correct_count} / {total_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04fb93a-de2a-4a56-9d16-6a1e4108b8f7",
   "metadata": {},
   "source": [
    "### Init experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c87f2a3-7f15-40a0-a98e-eb03a394e55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ckpt_file = 'ckpt_96_vocab_600_block_4_4_1.232val_15drop.pt' # pretty good - 28, 26, 29, 25, 26, 23, 30 5day - 27, 33, 7th: 25, 20, 15th (up 22): 23, 26\n",
    "# ckpt_file = 'ckpt_94_vocab_512_block_1.384val.pt' # good balance of up and down\n",
    "# ckpt_file = 'ckpt_96_vocab_600_block_4_6_1.256val.pt' # pretty good, didn't do 2023 too well - 27\n",
    "# ckpt_file = 'ckpt_96_vocab_600_block_4_6_1.224val_15drop.pt' # 27, 26, 25, 21\n",
    "# ckpt_file = 'ckpt_96_vocab_600_block_4_6_1.7M_1.227val_15drop.pt' # pretty good - 28, 31, 27, 27, 25, 26, 30 5day - 28, 29 (up 33), 7th: 22, 23, 15th: 14, 24\n",
    "\n",
    "# model = load_model(device, out_dir, ckpt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33d2fae9-0ec5-4351-b27e-9c2684ecd9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refresh the most recent data\n",
    "ticker = 'spy'\n",
    "\n",
    "get_ticker_data(\"^VIX\", f\"{currentDir}/data\", False, False)\n",
    "get_ticker_data(\"^TNX\", f\"{currentDir}/data\", False, False)\n",
    "ticker_sd, _ = get_ticker_data(ticker, f\"{currentDir}/data\", False, False)\n",
    "all_data_df = get_data_for_eval(ticker, data_dir=f\"{currentDir}/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65ed2ecd-0b42-4eb5-b57a-8961215dcb81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6563d89dce4a5c8bc990c476ef4b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_area = widgets.Output(layout={'border': '1px solid black', 'width': '100%', 'height': '2400px', 'overflow_y': 'scroll'})\n",
    "display(output_area)\n",
    "\n",
    "ckpt_files = ['ckpt_96_vocab_600_block_4_4_1.232val_15drop.pt', 'ckpt_96_vocab_600_block_4_6_1.7M_1.227val_15drop.pt', \n",
    "              'ckpt_96_vocab_600_block_4_4_1.2322val_20drop.pt', 'ckpt_96_vocab_600_block_4_6_1.7M_1.2331val_20drop.pt',\n",
    "              'rl_model_episode_90_acc_0.600.pt']\n",
    "ckpt_files = ['rl_model_episode_90_acc_0.600.pt', 'ckpt_96_vocab_600_block_4_6_1.7M_1.2331val_20drop.pt']\n",
    "# Generate plots within the scrollable output area\n",
    "with output_area:\n",
    "    for ckpt_file in ckpt_files:\n",
    "        model = load_model(device, out_dir, ckpt_file)\n",
    "        predict_and_plot(None, 20, all_data_df, ticker_sd.df, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f09c05-bd10-4174-8a76-b98f17c335e9",
   "metadata": {},
   "source": [
    "### backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff84a7ff-1110-4d6f-a6e0-ed3053ae764e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 1.57M\n",
      "GPTConfig(block_size=600, vocab_size=96, n_layer=4, n_head=6, n_embd=180, dropout=0.0, bias=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3359820b8f1f4399ae055de5ff85609d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ckpt_file = 'ckpt_96_vocab_600_block_4_6_1.7M_1.2331val_20drop.pt'\n",
    "# ckpt_file = 'ckpt_96_vocab_600_block_4_6_1.7M_1.2331val_20drop.pt'\n",
    "# ckpt_file = 'ckpt_96_vocab_600_block_4_4_1.232val_15drop.pt'\n",
    "# ckpt_file = 'ckpt_96_vocab_600_block_4_6_1.7M_1.227val_15drop.pt'\n",
    "backtest(load_model(device, out_dir, ckpt_file), all_data_df, ticker_sd.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0952e4-3882-4c82-a080-50819d4f058a",
   "metadata": {},
   "source": [
    "## Intraday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5228a356-23f8-4b9c-bd92-2774340d7e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before: the number of days before the current day. E.g. 1 means yesterday\n",
    "# Returns a datatime object that corresponds to the day_before at 18:55 minus predict_len * 5min\n",
    "def get_start_time_for_day_before(before: int, predict_len: int) -> datetime:\n",
    "    # Get the current date and time in UTC\n",
    "    current_time = datetime.now(pytz.timezone('America/Los_Angeles'))\n",
    "    \n",
    "    # Calculate the date before the specified number of days\n",
    "    day_before_date = current_time - timedelta(days=before)\n",
    "    \n",
    "    # Create a datetime object for the day_before_date at 11:55 Pacific time\n",
    "    end_time = day_before_date.replace(hour=11, minute=55, second=0, microsecond=0)\n",
    "    return end_time - timedelta(minutes=predict_len*5)    \n",
    "\n",
    "def backtest_intraday(model, data_for_eval, ticker_df):\n",
    "    # Create a scrollable output widget with a fixed height of 500 pixels\n",
    "    output_area = widgets.Output(layout={'border': '1px solid black', 'width': '100%', 'height': '2000px', 'overflow_y': 'scroll'})\n",
    "    display(output_area)\n",
    "    \n",
    "    # Generate plots within the scrollable output area\n",
    "    with output_area:\n",
    "        total_count = 0\n",
    "        correct_count = 0\n",
    "        for i in range(60):\n",
    "            start_time = get_start_time_for_day_before(i, predict_len)\n",
    "            if start_time.weekday() >= 5:\n",
    "                continue\n",
    "\n",
    "            total_count += 1\n",
    "            correct = predict_and_plot(start_time, predict_len, data_for_eval, ticker_df, model)\n",
    "            if correct:\n",
    "                print(\"correct\")\n",
    "                correct_count += 1\n",
    "    \n",
    "        print(f\"correction predictions {correct_count} / {total_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edce19c9-bfcc-4a0e-8499-35b3b95173d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 3.48M\n",
      "GPTConfig(block_size=600, vocab_size=96, n_layer=5, n_head=6, n_embd=240, dropout=0.0, bias=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ckpt_file = 'ckpt_intraday_96_vocab_1.7M_1.044val_15drop.pt'\n",
    "# ckpt_file = 'ckpt_96_vocab_600_block_4_4_1.232val_15drop.pt'\n",
    "# ckpt_file = 'ckpt_96_vocab_600_block_4_6_1.256val.pt' # pretty good, didn't do 2023 too well - 27\n",
    "# ckpt_file = 'ckpt_96_vocab_600_block_4_6_1.224val_15drop.pt' # 27, 26, 25, 21\n",
    "# ckpt_file = 'ckpt_96_vocab_600_block_4_6_1.7M_1.227val_15drop.pt' # pretty good - 28, 31, 27, 27, 25, 26, 30 5day - 28, 29 (up 33), 7th: 22, 23, 15th: 14, 24\n",
    "model = load_model(device, out_dir, \"ckpt.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77dd8193-9f11-4f72-9258-b282a525afb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f144783bca3477a9f3bdb870dedb651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ticker = 'SPY'\n",
    "predict_len = 10 # number of data points to predict\n",
    "cutoff_datetime = get_start_time_for_day_before(1, predict_len)\n",
    "\n",
    "get_ticker_data(\"^VIX\", f\"{currentDir}/data_intra_day\", intra_day=True, use_cache=False)\n",
    "get_ticker_data(\"^TNX\", f\"{currentDir}/data_intra_day\", intra_day=True, use_cache=False)\n",
    "ticker_sd, _ = get_ticker_data(ticker, f\"{currentDir}/data_intra_day\", intra_day=True, use_cache=False)\n",
    "all_data_df = get_data_for_eval(ticker, data_dir=f\"{currentDir}/data_intra_day\", intra_day=True)\n",
    "\n",
    "output_area = widgets.Output(layout={'border': '1px solid black', 'width': '100%', 'height': '2000px', 'overflow_y': 'scroll'})\n",
    "display(output_area)\n",
    "\n",
    "# Generate plots within the scrollable output area\n",
    "with output_area:\n",
    "    for _ in range(3):\n",
    "        predict_and_plot(cutoff_datetime, predict_len, all_data_df, ticker_sd.df, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fbb71c1-baef-41ee-b7fa-68212648e21e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "108ed161e40342cf8615d9ed0c907b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "backtest_intraday(model, all_data_df, ticker_sd.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e853f892-be0b-40a5-b7cd-c7d8880efb25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
